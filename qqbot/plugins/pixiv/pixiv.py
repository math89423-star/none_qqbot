import aiohttp
import asyncio
import json
import urllib.parse
import random
import sys
from urllib.parse import urlparse
import os
import re

# ====== é‡è¦é…ç½®ï¼ˆå¿…é¡»ä¿®æ”¹ï¼‰ ======
# 1. æœ¬åœ°ä»£ç†åœ°å€
PROXY = "http://127.0.0.1:7897"  # â† è¯·ä¿®æ”¹ä¸ºæ‚¨çš„å®é™…ä»£ç†åœ°å€
USE_PROXY = True

# 2. Cloudflare Workersåå‘ä»£ç†åœ°å€
PROXY_URL = "https://quiet-hill-31f3.math89423.workers.dev/"  # â† è¯·æ›¿æ¢ä¸ºæ‚¨çš„å®é™…Workersåœ°å€

# 3. ã€å…³é”®ã€‘ä»æµè§ˆå™¨è·å–Pixiv Cookie
#    å¦‚ä½•è·å–ï¼š
#    1. ç™»å½• https://www.pixiv.net
#    2. æŒ‰F12æ‰“å¼€å¼€å‘è€…å·¥å…·
#    3. åœ¨Application > Cookiesä¸­æ‰¾åˆ°pixiv.netçš„Cookie
#    4. å¤åˆ¶æ•´ä¸ªCookieå­—ç¬¦ä¸²ï¼ˆåŒ…å«PHPSESSID, device_tokenç­‰ï¼‰
#    5. å¡«å…¥ä¸‹æ–¹ï¼ˆç¤ºä¾‹æ ¼å¼ï¼šPHPSESSID=xxx; device_token=yyy; ...ï¼‰
PIXIV_COOKIE = "PHPSESSID=14916444_EuNtNE3Yd2ZZ50A7UzivUlxP7O2hLP7s; device_token=ccd49454e972c3b547f1db56a3560575; p_ab_id=1; p_ab_id_2=1"  # â† å¿…é¡»ä¿®æ”¹ï¼

# ====== æ ¸å¿ƒå‡½æ•° ======
async def search_pixiv_by_tag(tags: list, max_results=10) -> dict:
    """
    é€šè¿‡è§’è‰²æ ‡ç­¾æœç´¢Pixivå›¾ç‰‡ï¼ˆCookieè®¤è¯ç‰ˆï¼‰
    """
    # å°†æ ‡ç­¾ç”¨ç©ºæ ¼è¿æ¥å¹¶URLç¼–ç 
    search_tag = " ".join(tags)
    encoded_tag = urllib.parse.quote(search_tag)
    
    # æ„é€ æœç´¢URLï¼ˆä½¿ç”¨æœ€æ–°APIè·¯å¾„ï¼‰
    url = f"https://www.pixiv.net/ajax/search/artworks/{encoded_tag}"
    params = {
        "word": search_tag,
        "order": "date_d",
        "mode": "all",
        "p": 1,
        "s_mode": "s_tag",
        "type": "all",
        "lang": "zh",
        "version": "AAf5504c58-09e9-4e95-8c74-411a9311a4f1"
    }
    
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Referer": f"https://www.pixiv.net/tags/{encoded_tag}/artworks",
        "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
        "Cookie": PIXIV_COOKIE,  # â† å…³é”®ï¼šä½¿ç”¨æµè§ˆå™¨Cookieè®¤è¯
        "Sec-Fetch-Dest": "empty",
        "Sec-Fetch-Mode": "cors",
        "Sec-Fetch-Site": "same-origin",
        "X-Requested-With": "XMLHttpRequest"
    }
    
    try:
        proxy = PROXY if USE_PROXY else None
        
        async with aiohttp.ClientSession() as session:
            # ç¬¬ä¸€æ­¥ï¼šæœç´¢ä½œå“
            async with session.get(url, headers=headers, params=params, proxy=proxy) as response:
                if response.status != 200:
                    error_text = await response.text()
                    # å°è¯•æå–æœ‰æ„ä¹‰çš„é”™è¯¯ä¿¡æ¯
                    try:
                        error_json = json.loads(error_text)
                        error_msg = error_json.get("error", {}).get("message", error_text[:200])
                    except:
                        error_msg = error_text[:200]
                    raise Exception(f"æœç´¢APIå¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status}, è¯¦æƒ…: {error_msg}")
                
                data = await response.json()
                
                # æ£€æŸ¥è¿”å›æ•°æ®
                if not data.get("body") or not data["body"].get("illustManga"):
                    raise Exception("APIè¿”å›ç©ºæ•°æ®ï¼Œå¯èƒ½æ ‡ç­¾æ— æ•ˆæˆ–Cookieå¤±æ•ˆ")
                
                # æå–æœ‰æ•ˆä½œå“ï¼ˆè¿‡æ»¤å¹¿å‘Šå’Œæ— æ•ˆæ¡ç›®ï¼‰
                results = [
                    item for item in data["body"]["illustManga"]["data"] 
                    if item and isinstance(item, dict) and "id" in item and item.get("isAdContainer", 0) == 0
                ]
                
                if not results:
                    raise Exception("æœªæ‰¾åˆ°æœ‰æ•ˆä½œå“ï¼Œè¯·å°è¯•å…¶ä»–æ ‡ç­¾æˆ–æ£€æŸ¥Cookieæ˜¯å¦æœ‰æ•ˆ")
                
                print(f"âœ… æ‰¾åˆ° {len(results)} ä¸ªç›¸å…³ä½œå“ï¼Œæ­£åœ¨è·å–å›¾ç‰‡è¯¦æƒ…...")
                
                # éšæœºé€‰æ‹©ä¸€ä¸ªä½œå“
                selected = random.choice(results[:max_results])
                illust_id = selected["id"]
                
                # ç¬¬äºŒæ­¥ï¼šè·å–ä½œå“è¯¦æƒ…ï¼ˆåŒ…å«åŸå§‹å›¾ç‰‡URLï¼‰
                illust_url = f"https://www.pixiv.net/ajax/illust/{illust_id}"
                illust_headers = {
                    **headers,
                    "Referer": f"https://www.pixiv.net/artworks/{illust_id}"
                }
                
                async with session.get(illust_url, headers=illust_headers, proxy=proxy) as illust_response:
                    if illust_response.status != 200:
                        error_text = await illust_response.text()
                        raise Exception(f"è·å–ä½œå“è¯¦æƒ…å¤±è´¥ï¼ŒçŠ¶æ€ç : {illust_response.status}, å“åº”: {error_text[:200]}")
                    
                    illust_data = await illust_response.json()
                    if illust_data.get("error"):
                        raise Exception(f"ä½œå“è¯¦æƒ…APIé”™è¯¯: {illust_data['message']}")
                    
                    illust_body = illust_data["body"]
                    
                    # æå–åŸå§‹å›¾ç‰‡URL
                    original_img_url = illust_body["urls"]["original"]
                    regular_img_url = illust_body["urls"]["regular"]
                    
                    # é€šè¿‡åå‘ä»£ç†æ›¿æ¢å›¾ç‰‡URL
                    proxy_original_url = replace_image_domain(original_img_url)
                    proxy_preview_url = replace_image_domain(regular_img_url)
                    
                    return {
                        "image_url": proxy_original_url,
                        "pid": str(illust_id),
                        "title": illust_body["title"],
                        "author": illust_body["userName"],
                        "author_id": illust_body["userId"],
                        "work_url": f"https://www.pixiv.net/artworks/{illust_id}",
                        "preview_url": proxy_preview_url
                    }
                
    except Exception as e:
        raise Exception(f"æœç´¢å¤±è´¥: {str(e)}")

def replace_image_domain(url: str) -> str:
    """å°†Pixivå›¾ç‰‡åŸŸåæ›¿æ¢ä¸ºä»£ç†åŸŸå"""
    if not url.startswith("http"):
        url = "https:" + url
    
    # æ ‡å‡†åŒ–ä»£ç†URL
    proxy_base = PROXY_URL.rstrip('/') + '/'
    
    # ç›´æ¥æ›¿æ¢åŸŸåéƒ¨åˆ†
    if "i.pximg.net" in url:
        return url.replace("https://i.pximg.net", proxy_base.rstrip('/'))
    elif "pixiv.cat" in url:
        return url.replace("https://pixiv.cat", proxy_base.rstrip('/'))
    
    # é€šç”¨å¤„ç†
    path = url.replace("https://", "").replace("http://", "")
    return proxy_base + path

# ====== å‘½ä»¤è¡Œæ¥å£ ======
def main():
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•: python pixiv_pic.py <tag1> <tag2> ...")
        print("ç¤ºä¾‹: python pixiv_pic.py é¸£æ½®")
        print("\nâš ï¸ é‡è¦é…ç½®è¯´æ˜ âš ï¸")
        print("1. å¿…é¡»è®¾ç½®æœ‰æ•ˆçš„Pixiv Cookie (PIXIV_COOKIEå˜é‡)")
        print("   - ç™»å½•pixiv.netåï¼Œä»æµè§ˆå™¨å¼€å‘è€…å·¥å…·å¤åˆ¶å®Œæ•´Cookie")
        print("2. ä»£ç†é…ç½® (PROXY): ç¡®ä¿ä»£ç†è½¯ä»¶å·²å¯åŠ¨")
        print("3. Cloudflare Workers (PROXY_URL): å¿…é¡»æ­£ç¡®éƒ¨ç½²")
        print("\nğŸ“š å¦‚ä½•è·å–Cookie:")
        print("   a) Chrome: F12 â†’ Application â†’ Cookies â†’ https://www.pixiv.net")
        print("   b) å¤åˆ¶æ•´ä¸ªCookieå­—ç¬¦ä¸²ï¼ˆåŒ…å«PHPSESSID, device_tokenç­‰ï¼‰")
        print("   c) å¡«å…¥ä»£ç ä¸­çš„PIXIV_COOKIEå˜é‡")
        sys.exit(1)
    
    # æ£€æŸ¥Cookieæ˜¯å¦å·²é…ç½®
    if "æ‚¨çš„ä¼šè¯ID" in PIXIV_COOKIE or len(PIXIV_COOKIE) < 50:
        print("\nâŒ é”™è¯¯: æœªé…ç½®æœ‰æ•ˆçš„Pixiv Cookie!")
        print("è¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤é…ç½®:")
        print("1. ç™»å½• https://www.pixiv.net")
        print("2. æŒ‰F12æ‰“å¼€å¼€å‘è€…å·¥å…·")
        print("3. è½¬åˆ°Application > Cookies > https://www.pixiv.net")
        print("4. å¤åˆ¶æ•´ä¸ªCookieå­—ç¬¦ä¸²ï¼ˆåŒ…å«PHPSESSID, device_tokenç­‰ï¼‰")
        print("5. æ›¿æ¢ä»£ç ä¸­çš„PIXIV_COOKIEå˜é‡å€¼")
        sys.exit(1)
    
    tags = sys.argv[1:]
    print(f"ğŸ” æ­£åœ¨æœç´¢æ ‡ç­¾: {', '.join(tags)}")
    print("â³ è¯·ç¨å€™...ï¼ˆéœ€è¦ç½‘ç»œè¿æ¥ï¼Œè¯·ç¡®ä¿ä»£ç†å·²å¯åŠ¨ï¼‰")
    print(f"ğŸŒ ä»£ç†åœ°å€: {PROXY}")
    print(f"ğŸ›¡ï¸  ä»£ç†æœåŠ¡: {PROXY_URL}")
    
    try:
        result = asyncio.run(search_pixiv_by_tag(tags))
        
        # æ‰“å°ç¾åŒ–ç»“æœ
        print("\n" + "="*50)
        print(f"ğŸ¨ ä½œå“æ ‡é¢˜: {result['title']}")
        print(f"ğŸ‘¤ ä½œè€…: {result['author']} (ID: {result['author_id']})")
        print(f"ğŸ†” ä½œå“ID: {result['pid']}")
        print(f"ğŸ”— ä½œå“é“¾æ¥: {result['work_url']}")
        print("-"*50)
        print(f"ğŸ–¼ï¸  é¢„è§ˆå›¾: {result['preview_url']}")
        print(f"ğŸ’¾ åŸå›¾: {result['image_url']}")
        print("="*50)
        print("\nâœ… æˆåŠŸè·å–å›¾ç‰‡ä¿¡æ¯ï¼")
        
        # å¤åˆ¶åˆ°å‰ªè´´æ¿
        try:
            import pyperclip
            pyperclip.copy(result['image_url'])
            print("ğŸ“‹ åŸå›¾URLå·²å¤åˆ¶åˆ°å‰ªè´´æ¿")
        except ImportError:
            print("ğŸ’¡ æç¤º: å®‰è£…pyperclipå¯è‡ªåŠ¨å¤åˆ¶URL: pip install pyperclip")
            
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {str(e)}")
        print("\nğŸ” é—®é¢˜æ’æŸ¥æŒ‡å—:")
        print("1ï¸âƒ£  Cookieé—®é¢˜ (æœ€å¸¸è§):")
        print("   - æ£€æŸ¥PIXIV_COOKIEæ˜¯å¦å®Œæ•´æœ‰æ•ˆ")
        print("   - é‡æ–°ç™»å½•Pixivå¹¶æ›´æ–°Cookie")
        print("   - ç¡®ä¿CookieåŒ…å«PHPSESSIDå’Œdevice_token")
        print("2ï¸âƒ£  ä»£ç†é—®é¢˜:")
        print(f"   - æµ‹è¯•ä»£ç†: curl -x {PROXY} https://www.pixiv.net")
        print("3ï¸âƒ£  Cloudflare Workersé—®é¢˜:")
        print(f"   - æµ‹è¯•ä»£ç†å›¾ç‰‡: {PROXY_URL}img-original/img/2023/01/01/00/00/00/12345678_p0.jpg")
        print("4ï¸âƒ£  ç½‘ç»œé—®é¢˜:")
        print("   - ç¡®ä¿ä»£ç†è½¯ä»¶å…¨å±€æ¨¡å¼å·²å¼€å¯")
        print("   - å°è¯•é‡å¯ä»£ç†è½¯ä»¶")
        sys.exit(1)

if __name__ == "__main__":
    main()